{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T19:27:23.665689Z",
     "start_time": "2018-04-12T19:27:20.582747Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import helpers as hp\n",
    "import pickle as pkl\n",
    "import itertools as it\n",
    "\n",
    "from collections import OrderedDict, defaultdict\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score,\\\n",
    "                            average_precision_score, roc_auc_score,\\\n",
    "                            roc_curve, precision_recall_curve, confusion_matrix,\\\n",
    "                            accuracy_score, classification_report\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from matplotlib import rcParams\n",
    "from importlib import reload\n",
    "from model_generator import deep_er_model_generator\n",
    "pd.options.display.max_colwidth = 1000\n",
    "\n",
    "rcParams['font.family'] = 'serif'\n",
    "rcParams['font.serif'] = 'times new roman'\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T21:41:12.001384Z",
     "start_time": "2018-04-12T21:40:47.012379Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reload(hp)\n",
    "\n",
    "with open('../data/embeddings/glove-300.map', 'rb') as f:\n",
    "    map = pkl.load(f)\n",
    "\n",
    "data_dir = os.path.join('..','data')\n",
    "source_dir = os.path.join(data_dir,'split','dblp-scholar')\n",
    "data = hp.load_data(source_dir)\n",
    "\n",
    "datasets = ['train_1', 'val_1', 'test_1', 'train_2', 'val_2', 'test_2']\n",
    "\n",
    "for data_name in datasets:\n",
    "    data[data_name] = data[data_name].fillna(0)\n",
    "\n",
    "doc_freqs_1, doc_freqs_2 = hp.get_document_frequencies('../data/converted/dblp-scholar/', mapping=map)\n",
    "nan_idx = map['word2idx']['NaN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T21:41:28.691606Z",
     "start_time": "2018-04-12T21:41:20.426588Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "histories = dict(acc=list(), val_acc=list(), loss=list(), val_loss=list())\n",
    "model, X_train, X_val, X_test, y_train, y_val, y_test = \\\n",
    "deep_er_model_generator(data,\n",
    "                        embedding_file = '../data/embeddings/glove-300.matrix.npy',\n",
    "                        text_columns = ['title', 'authors', 'venue'],\n",
    "                        numeric_columns = [],\n",
    "                        text_nan_idx=nan_idx,\n",
    "                        num_nan_val=0,\n",
    "                        text_sim_metrics=['cosine'],\n",
    "                        text_compositions=['average'],\n",
    "                        numeric_sim_metrics=['min_max_ratio', 'scaled_inverse_lp', 'unscaled_inverse_lp'],\n",
    "                        dense_nodes=[32, 16, 8],\n",
    "                        document_frequencies=(doc_freqs_1, doc_freqs_2),\n",
    "                        idf_smoothing=2,\n",
    "                        make_isna=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T21:52:12.328428Z",
     "start_time": "2018-04-12T21:51:42.009377Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=8192,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    shuffle=True)\n",
    "\n",
    "histories['acc'].extend(history.history['acc'])\n",
    "histories['val_acc'].extend(history.history['val_acc'])\n",
    "histories['loss'].extend(history.history['loss'])\n",
    "histories['val_loss'].extend(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T21:53:06.430610Z",
     "start_time": "2018-04-12T21:53:06.048975Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16,6))\n",
    "axes[0].plot(histories['loss'], label='loss')\n",
    "axes[0].plot(histories['val_loss'], label='val_loss')\n",
    "axes[0].set_ylim(0, 0.1)\n",
    "axes[1].plot(histories['acc'], label='acc')\n",
    "axes[1].plot(histories['val_acc'], label='val_acc')\n",
    "axes[1].set_ylim(.8, 1)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    ax.set(xlabel='epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T21:53:11.515998Z",
     "start_time": "2018-04-12T21:53:08.723045Z"
    }
   },
   "outputs": [],
   "source": [
    "y_val_pred = model.predict(X_val, batch_size=8192)[:,1]\n",
    "y_val_ = data['val_y'].values.squeeze()\n",
    "print(classification_report(y_val_, y_val_pred >= 0.5))\n",
    "print(confusion_matrix(y_val_, y_val_pred >= 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T21:45:49.865322Z",
     "start_time": "2018-04-12T21:45:47.406682Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapping = map.copy()\n",
    "bool_mask = (y_val_ == 1) & ~(y_val_pred >= 0.5)\n",
    "columns = ['title', 'authors', 'venue']\n",
    "df_examine = hp.examine_data(data['val_1'], data['val_2'], columns, bool_mask, mapping)\n",
    "df_examine.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model and histories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T21:51:21.415206Z",
     "start_time": "2018-04-12T21:51:21.050809Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(histories).to_csv('../data/histories/dblp-scholar.csv', index=False)\n",
    "model.save_weights('../data/models/dblp-scholar-base-1-num-null')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T21:51:26.898830Z",
     "start_time": "2018-04-12T21:51:23.802014Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_weights('../data/models/dblp-scholar-base-1-num-null')\n",
    "y_test_pred = model.predict(X_test, batch_size=8192)[:,1]\n",
    "y_test_ = data['test_y'].values.squeeze()\n",
    "print(classification_report(y_test_, y_test_pred >= 0.5, digits=5))\n",
    "print(confusion_matrix(y_test_, y_test_pred >= 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(y_test_) - set(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
